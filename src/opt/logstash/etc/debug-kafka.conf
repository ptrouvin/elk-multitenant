input { 
	stdin { }
	kafka {
		zk_connect => "localhost:2181"
		topic_id => logstash
	}
}

filter {
  grok {
    match => [ "message", "%{COMMONAPACHELOG}" ]
	match => [ "message", "%{COMBINEDAPACHELOG}" ]
	match => [ "message", "LID=%{WORD:LID} (?<json_message>.*)" ]
  }
  if [json_message] {
	json {
		source => json_message
	}
	mutate { remove_field => [ "json_message", "_grokparsefailure" ] }
  }
  date {
    match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
  }
  ruby {
     code => "
                    #event['index_day'] = event['@timestamp'].localtime.strftime('%Y.%m.%d')
                    event['index_day'] = Time.now.localtime.strftime('%Y.%m.%d')
            "
  }
}

output {
#	elasticsearch { 
#		host => localhost
#		index => "logstash-%{index_day}"
#	}
  if ! [LID] {
    kafka {
		broker_list => "localhost:9092"
		topic_id => logstashOut
	}
  }
  stdout { codec => rubydebug }
}
